ARG TRT_IMAGE_TAG=24.12-py3
ARG TENSORRT_IMAGE=nvcr.io/nvidia/tensorrt:${TRT_IMAGE_TAG}
ARG CUDA_DEPS=/tmp/cuda_deps/

FROM ${TENSORRT_IMAGE} AS builder

ARG CUDA_DEPS

RUN mkdir -p ${CUDA_DEPS}/{bin,lib,include/cuda,include/tensorrt,opt/tensorrt,usr/local}

RUN cp -r /usr/local/cuda ${CUDA_DEPS}/usr/local
RUN cp -a /usr/local/cuda/lib64/*.so* ${CUDA_DEPS}/lib/
RUN for lib in nvinfer nvonnxparser nvparsers nvinfer_plugin; do \
      cp -a /usr/lib/$(dpkg-architecture -qDEB_HOST_MULTIARCH)/lib${lib}*.so* \
         ${CUDA_DEPS}/lib/ 2>/dev/null || : ; \
    done
RUN for hdr in NvInfer NvOnnxParser NvParsers; do \
      cp -a /usr/include/$(dpkg-architecture -qDEB_HOST_MULTIARCH)/${hdr}* \
         ${CUDA_DEPS}/include/tensorrt/ 2>/dev/null || : ; \
    done
RUN cp -a /opt/tensorrt ${CUDA_DEPS}/opt/ 2>/dev/null || :
RUN cp -a /opt/cuda ${CUDA_DEPS}/opt/ 2>/dev/null || :

RUN PYV=$(python3 -c "import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}')") \
  && echo $PYV > ${CUDA_DEPS}/PYTHON_VERSION.txt \
  && mkdir -p ${CUDA_DEPS}/usr/lib/python${PYV}/dist-packages \
  && cp -a /usr/local/lib/python${PYV}/dist-packages/tensorrt* \
          ${CUDA_DEPS}/usr/lib/python${PYV}/dist-packages/ 2>/dev/null || : \
  && cp -a /usr/local/lib/python${PYV}/dist-packages/_pywrap_tensorRT.so* \
          ${CUDA_DEPS}/usr/lib/python${PYV}/dist-packages/ 2>/dev/null || : \
  && cp -a /usr/local/lib/python${PYV}/dist-packages/pycuda \
          ${CUDA_DEPS}/usr/lib/python${PYV}/dist-packages/ 2>/dev/null || : \
  && cp -a /usr/local/lib/python${PYV}/dist-packages/polygraphy \
         ${CUDA_DEPS}/usr/lib/python${PYV}/dist-packages/ 2>/dev/null || :

RUN printenv | \
    grep -E '(CUDA|_CUDA|CUDNN|CURAND|CUBLAS|CUSOLVER|CUFFT|CUTENSOR|NPP|NCCL|NVIDIA|TENSORRT|POLYGRAPHY|NSIGHT|TRANSFORMER_ENGINE|HPCX|OPENUCX|EFA|MOFED|AWS_OFI_NCCL|LD_LIBRARY_PATH|PATH)' \
  | while IFS='=' read -r key val; do \
      if [ "$key" = "PATH" ]; then \
        printf 'export PATH="$PATH:%s"\n' "$val"; \
      elif [ "$key" = "LD_LIBRARY_PATH" ]; then \
        printf 'export LD_LIBRARY_PATH="$LD_LIBRARY_PATH:%s"\n' "$val"; \
      else \
        printf 'export %s="%s"\n' "$key" "$val"; \
      fi; \
    done > ${CUDA_DEPS}/cuda_env.sh
RUN echo 'export NVIDIA_VISIBLE_DEVICES=all' >> ${CUDA_DEPS}/cuda_env.sh \
  && echo 'export NVIDIA_DRIVER_CAPABILITIES=compute,utility' >> ${CUDA_DEPS}/cuda_env.sh

RUN chown -R 1000:1000 ${CUDA_DEPS}/cuda_env.sh
RUN chmod +x ${CUDA_DEPS}/cuda_env.sh

FROM scratch AS final-builder

ARG CUDA_DEPS
WORKDIR /

COPY --from=builder ${CUDA_DEPS} /deps

# ! this is me exploiting a bug we have (it's ugly, I know), we need a much more consistent way to handle this
# ! but helps for debugging and development for now...
COPY --from=builder ${CUDA_DEPS}/cuda_env.sh /ws/install/aica_event_engine/apt/opt/ros/jazzy/setup.bash

COPY --from=builder ${CUDA_DEPS}/bin/ /usr/bin
COPY --from=builder ${CUDA_DEPS}/lib/ /usr/lib
COPY --from=builder ${CUDA_DEPS}/usr/local/cuda/ /usr/local/cuda
COPY --from=builder ${CUDA_DEPS}/include/ /usr/include
COPY --from=builder ${CUDA_DEPS}/opt/ /opt
COPY --from=builder ${CUDA_DEPS}/usr/lib/ /usr/lib

FROM scratch  

COPY --from=final-builder /ws/ /ws
COPY --from=final-builder /usr/ /usr
COPY --from=final-builder /opt/ /opt

ARG VERSION=0.0.0
LABEL org.opencontainers.image.title="AICA Cuda libraries"
LABEL org.opencontainers.image.description="AICA Cuda libraries"
LABEL org.opencontainers.image.version="${VERSION}"
LABEL tech.aica.image.metadata='{"type":"lib"}'